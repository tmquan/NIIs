{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "import typing\n",
    "from typing import Any, Callable, Optional, Sequence, Union, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import monai \n",
    "from monai.data import Dataset, ArrayDataset, CacheDataset, DataLoader\n",
    "from monai.data import list_data_collate, decollate_batch\n",
    "from monai.utils import first, set_determinism, get_seed, MAX_SEED\n",
    "from monai.transforms import (\n",
    "    apply_transform, \n",
    "    Transform, MapTransform, DivisiblePad,\n",
    "    AddChanneld,\n",
    "    Compose, OneOf, \n",
    "    LoadImaged, SaveImaged, Spacingd,\n",
    "    Orientationd, DivisiblePadd, \n",
    "    RandFlipd, RandZoomd, RandScaleCropd, RandSpatialCropd,\n",
    "    RandHistogramShiftd, RandAffined,\n",
    "    Resized, Rotate90d, Flipd, \n",
    "    ScaleIntensityd,\n",
    "    ScaleIntensityRanged, HistogramNormalized,\n",
    "    ToTensord,\n",
    ")\n",
    "from pytorch_lightning import LightningDataModule\n",
    "\n",
    "import pytorch3d\n",
    "from pytorch3d.structures import Volumes\n",
    "from pytorch3d.renderer.camera_utils import join_cameras_as_batch\n",
    "from pytorch3d.renderer.cameras import (\n",
    "    camera_position_from_spherical_angles,\n",
    "    CamerasBase,\n",
    "    FoVOrthographicCameras,\n",
    "    FoVPerspectiveCameras,\n",
    "    get_world_to_view_transform,\n",
    "    look_at_rotation,\n",
    "    look_at_view_transform,\n",
    "    OpenGLOrthographicCameras,\n",
    "    OpenGLPerspectiveCameras,\n",
    "    OrthographicCameras,\n",
    "    PerspectiveCameras,\n",
    "    SfMOrthographicCameras,\n",
    "    SfMPerspectiveCameras,\n",
    ")\n",
    "from pytorch3d.transforms import Transform3d\n",
    "from pytorch3d.transforms.rotation_conversions import random_rotations\n",
    "from pytorch3d.transforms.so3 import so3_exp_map\n",
    "from pytorch3d.renderer import VolumeRenderer\n",
    "from pytorch3d.renderer import VolumeSampler\n",
    "from pytorch3d.renderer import NDCMultinomialRaysampler\n",
    "from pytorch3d.renderer import ray_bundle_to_ray_points\n",
    "from pytorch3d.renderer import RayBundle\n",
    "from pytorch3d.renderer import EmissionAbsorptionRaymarcher\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnpairedDataset(monai.data.Dataset, monai.transforms.Randomizable):\n",
    "    def __init__(\n",
    "        self,\n",
    "        keys: Sequence, \n",
    "        data: Sequence, \n",
    "        transform: Optional[Callable] = None,\n",
    "        length: Optional[Callable] = None, \n",
    "        batch_size: int = 32, \n",
    "    ) -> None:\n",
    "        self.keys = keys\n",
    "        self.data = data\n",
    "        self.length = length\n",
    "        self.batch_size = batch_size\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        if self.length is None:\n",
    "            return min((len(dataset) for dataset in self.data))\n",
    "        else: \n",
    "            return self.length\n",
    "\n",
    "    def _transform(self, index: int):\n",
    "        data = {}\n",
    "        self.R.seed(index)\n",
    "        for key, dataset in zip(self.keys, self.data):\n",
    "            rand_idx = self.R.randint(0, len(dataset)) \n",
    "            data[key] = dataset[rand_idx]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            data = apply_transform(self.transform, data)\n",
    "\n",
    "        return data\n",
    "\n",
    "class CustomDataModule(LightningDataModule):\n",
    "    def __init__(self, \n",
    "        train_image3d_folders: str = \"path/to/folder\", \n",
    "        train_image2d_folders: str = \"path/to/folder\", \n",
    "        val_image3d_folders: str = \"path/to/folder\", \n",
    "        val_image2d_folders: str = \"path/to/folder\", \n",
    "        test_image3d_folders: str = \"path/to/folder\", \n",
    "        test_image2d_folders: str = \"path/to/dir\", \n",
    "        shape: int = 256,\n",
    "        batch_size: int = 32\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.shape = shape\n",
    "        # self.setup() \n",
    "        self.train_image3d_folders = train_image3d_folders\n",
    "        self.train_image2d_folders = train_image2d_folders\n",
    "        self.val_image3d_folders = val_image3d_folders\n",
    "        self.val_image2d_folders = val_image2d_folders\n",
    "        self.test_image3d_folders = test_image3d_folders\n",
    "        self.test_image2d_folders = test_image2d_folders\n",
    "\n",
    "        # self.setup()\n",
    "        def glob_files(folders: str=None, extension: str='*.nii.gz'):\n",
    "            assert folders is not None\n",
    "            paths = [glob.glob(os.path.join(folder, extension), recursive = True) for folder in folders]\n",
    "            files = sorted([item for sublist in paths for item in sublist])\n",
    "            print(len(files))\n",
    "            print(files[:1])\n",
    "            return files\n",
    "            \n",
    "        self.train_image3d_files = glob_files(folders=train_image3d_folders, extension='**/*.nii.gz')\n",
    "        self.train_image2d_files = glob_files(folders=train_image2d_folders, extension='**/*.png')\n",
    "        \n",
    "        self.val_image3d_files = glob_files(folders=val_image3d_folders, extension='**/*.nii.gz') # TODO\n",
    "        self.val_image2d_files = glob_files(folders=val_image2d_folders, extension='**/*.png')\n",
    "        \n",
    "        self.test_image3d_files = glob_files(folders=test_image3d_folders, extension='**/*.nii.gz') # TODO\n",
    "        self.test_image2d_files = glob_files(folders=test_image2d_folders, extension='**/*.png')\n",
    "\n",
    "\n",
    "    def setup(self, stage: Optional[str]=None):\n",
    "        # make assignments here (val/train/test split)\n",
    "        # called on every process in DDP\n",
    "        set_determinism(seed=2222)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        self.train_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image3d\", \"image2d\"]),\n",
    "                AddChanneld(keys=[\"image3d\", \"image2d\"],),\n",
    "                Spacingd(keys=[\"image3d\"], pixdim=(1.0, 1.0, 1.0), mode=[\"bilinear\"]),  \n",
    "                Rotate90d(keys=[\"image2d\"], k=3),\n",
    "                OneOf([\n",
    "                    Orientationd( keys=('image3d'), axcodes=\"ALI\"),\n",
    "                    Orientationd( keys=('image3d'), axcodes=\"PLI\"),\n",
    "                    Orientationd( keys=('image3d'), axcodes=\"ARI\"),\n",
    "                    Orientationd( keys=('image3d'), axcodes=\"PRI\"),\n",
    "                    # Orientationd( keys=[\"image3d\"], axcodes=\"LPI\"),\n",
    "                    # Orientationd( keys=[\"image3d\"], axcodes=\"RPI\"),\n",
    "                    # Orientationd( keys=[\"image3d\"], axcodes=\"LAI\"),\n",
    "                    # Orientationd( keys=[\"image3d\"], axcodes=\"RAI\"),\n",
    "                    ],\n",
    "                ),\n",
    "                ScaleIntensityd(keys=[\"image2d\"], minv=0.0, maxv=1.0,),\n",
    "                ScaleIntensityRanged(keys=[\"image3d\"], clip=True,  # Full range\n",
    "                        a_min=-500, #-200, \n",
    "                        a_max=3071, #1500,\n",
    "                        b_min=0.0,\n",
    "                        b_max=1.0),\n",
    "                # RandFlipd(keys=[\"image3d\"], prob=0.5, spatial_axis=0),\n",
    "                RandZoomd(keys=[\"image3d\"], prob=1.0, min_zoom=0.9, max_zoom=1.0, padding_mode='constant', mode=[\"trilinear\"], align_corners=True), \n",
    "                RandZoomd(keys=[\"image2d\"], prob=1.0, min_zoom=0.9, max_zoom=1.0, padding_mode='constant', mode=[\"area\"]), \n",
    "                RandFlipd(keys=[\"image2d\"], prob=0.5, spatial_axis=1),\n",
    "                RandScaleCropd(keys=[\"image3d\"], \n",
    "                               roi_scale=(0.9, 0.9, 0.8), \n",
    "                               max_roi_scale=(1.0, 1.0, 0.8), \n",
    "                               random_center=True, \n",
    "                               random_size=True),\n",
    "                RandAffined(keys=[\"image3d\"], rotate_range=None, shear_range=None, translate_range=20, scale_range=None),\n",
    "                Resized(keys=[\"image3d\"], spatial_size=256, size_mode=\"longest\", mode=[\"trilinear\"], align_corners=True),\n",
    "                Resized(keys=[\"image2d\"], spatial_size=256, size_mode=\"longest\", mode=[\"area\"]),\n",
    "                DivisiblePadd(keys=[\"image3d\", \"image2d\"], k=256, mode=\"constant\", constant_values=0),\n",
    "                \n",
    "                ToTensord(keys=[\"image3d\", \"image2d\"],),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.train_datasets = UnpairedDataset(\n",
    "            keys=[\"image3d\", \"image2d\"],\n",
    "            data=[self.train_image3d_files, self.train_image2d_files], \n",
    "            transform=self.train_transforms,\n",
    "            length=1000,\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "\n",
    "        self.train_loader = DataLoader(\n",
    "            self.train_datasets, \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=8, \n",
    "            collate_fn=list_data_collate,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        return self.train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        self.val_transforms = Compose(\n",
    "            [\n",
    "                LoadImaged(keys=[\"image3d\", \"image2d\"]),\n",
    "                AddChanneld(keys=[\"image3d\", \"image2d\"],),\n",
    "                Spacingd(keys=[\"image3d\"], pixdim=(1.0, 1.0, 1.0), mode=[\"bilinear\"]),  \n",
    "                Rotate90d(keys=[\"image2d\"], k=3),\n",
    "                OneOf([\n",
    "                    Orientationd( keys=('image3d'), axcodes=\"ALI\"),\n",
    "                    Orientationd( keys=('image3d'), axcodes=\"PLI\"),\n",
    "                    Orientationd( keys=('image3d'), axcodes=\"ARI\"),\n",
    "                    Orientationd( keys=('image3d'), axcodes=\"PRI\"),\n",
    "                    # Orientationd( keys=[\"image3d\"], axcodes=\"LPI\"),\n",
    "                    # Orientationd( keys=[\"image3d\"], axcodes=\"RPI\"),\n",
    "                    # Orientationd( keys=[\"image3d\"], axcodes=\"LAI\"),\n",
    "                    # Orientationd( keys=[\"image3d\"], axcodes=\"RAI\"),\n",
    "                    ],\n",
    "                ), \n",
    "                ScaleIntensityd(keys=[\"image2d\"], minv=0.0, maxv=1.0,),\n",
    "                ScaleIntensityRanged(keys=[\"image3d\"], clip=True,  # Full range\n",
    "                        a_min=-500, #-200, \n",
    "                        a_max=3071, #1500,\n",
    "                        b_min=0.0,\n",
    "                        b_max=1.0),\n",
    "                Resized(keys=[\"image3d\"], spatial_size=256, size_mode=\"longest\", mode=[\"trilinear\"], align_corners=True),\n",
    "                Resized(keys=[\"image2d\"], spatial_size=256, size_mode=\"longest\", mode=[\"area\"]),\n",
    "                DivisiblePadd(keys=[\"image3d\", \"image2d\"], k=256, mode=\"constant\", constant_values=0),\n",
    "            \n",
    "                ToTensord(keys=[\"image3d\", \"image2d\"],),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.val_datasets = UnpairedDataset(\n",
    "            keys=[\"image3d\", \"image2d\"],\n",
    "            data=[self.val_image3d_files, self.val_image2d_files], \n",
    "            transform=self.val_transforms,\n",
    "            length=200,\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "        \n",
    "        self.val_loader = DataLoader(\n",
    "            self.val_datasets, \n",
    "            batch_size=self.batch_size, \n",
    "            num_workers=4, \n",
    "            collate_fn=list_data_collate,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        return self.val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hparams(object):\n",
    "    def __init__(self, datadir, shape=256, batch_size=1):\n",
    "        self.datadir = datadir\n",
    "        self.shape = shape\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "hparams = Hparams(datadir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data module\n",
    "train_image3d_folders = [\n",
    "    os.path.join(hparams.datadir, 'SpineXRVertSegmentation/Verse2019/raw/train/rawdata/'),\n",
    "    os.path.join(hparams.datadir, 'SpineXRVertSegmentation/Verse2020/raw/train/rawdata/'),\n",
    "    os.path.join(hparams.datadir, 'SpineXRVertSegmentation/Verse2019/raw/val/rawdata/'),\n",
    "    os.path.join(hparams.datadir, 'SpineXRVertSegmentation/Verse2020/raw/val/rawdata/'),\n",
    "    os.path.join(hparams.datadir, 'SpineXRVertSegmentation/Verse2019/raw/test/rawdata/'),\n",
    "    os.path.join(hparams.datadir, 'SpineXRVertSegmentation/Verse2020/raw/test/rawdata/'),\n",
    "\n",
    "    os.path.join(hparams.datadir, 'SpineXRVertSegmentation/UWSpine/processed/train/images'),\n",
    "    os.path.join(hparams.datadir, 'SpineXRVertSegmentation/UWSpine/processed/test/images/'),\n",
    "\n",
    "    os.path.join(hparams.datadir, 'ChestXRLungSegmentation/NSCLC/processed/train/images'),\n",
    "    os.path.join(hparams.datadir, 'ChestXRLungSegmentation/MOSMED/processed/train/images/CT-0'),\n",
    "    os.path.join(hparams.datadir, 'ChestXRLungSegmentation/MOSMED/processed/train/images/CT-1'),\n",
    "    os.path.join(hparams.datadir, 'ChestXRLungSegmentation/MOSMED/processed/train/images/CT-2'),\n",
    "    os.path.join(hparams.datadir, 'ChestXRLungSegmentation/MOSMED/processed/train/images/CT-3'),\n",
    "    os.path.join(hparams.datadir, 'ChestXRLungSegmentation/MOSMED/processed/train/images/CT-4'),\n",
    "    os.path.join(hparams.datadir, 'ChestXRLungSegmentation/Imagenglab/processed/train/images'),\n",
    "]\n",
    "train_label3d_folders = [\n",
    "\n",
    "]\n",
    "\n",
    "train_image2d_folders = [\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/JSRT/processed/images/'), \n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/ChinaSet/processed/images/'), \n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/Montgomery/processed/images/'),\n",
    "    os.path.join(hparams.datadir, 'ChestXRLungSegmentation/VinDr/v1/processed/train/images/'), \n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/VinDr/v1/processed/test/images/'), \n",
    "    # os.path.join(hparams.datadir, 'SpineXRVertSegmentation/T62020/20200501/raw/images'), \n",
    "    # os.path.join(hparams.datadir, 'SpineXRVertSegmentation/T62021/20211101/raw/images'), \n",
    "    os.path.join(hparams.datadir, 'SpineXRVertSegmentation/VinDr/v1/processed/train/images/'), \n",
    "    # os.path.join(hparams.datadir, 'SpineXRVertSegmentation/VinDr/v1/processed/test/images/'), \n",
    "]\n",
    "train_label2d_folders = [\n",
    "]\n",
    "\n",
    "val_image3d_folders = train_image3d_folders\n",
    "val_image2d_folders = [\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/JSRT/processed/images/'), \n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/ChinaSet/processed/images/'), \n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/Montgomery/processed/images/'),\n",
    "    # os.path.join(hparams.datadir, 'ChestXRLungSegmentation/VinDr/v1/processed/train/images/'), \n",
    "    os.path.join(hparams.datadir, 'ChestXRLungSegmentation/VinDr/v1/processed/test/images/'), \n",
    "    # os.path.join(hparams.datadir, 'SpineXRVertSegmentation/T62020/20200501/raw/images'), \n",
    "    # os.path.join(hparams.datadir, 'SpineXRVertSegmentation/T62021/20211101/raw/images'), \n",
    "    # os.path.join(hparams.datadir, 'SpineXRVertSegmentation/VinDr/v1/processed/train/images/'), \n",
    "    os.path.join(hparams.datadir, 'SpineXRVertSegmentation/VinDr/v1/processed/test/images/'), \n",
    "]\n",
    "\n",
    "test_image3d_folders = val_image3d_folders\n",
    "test_image2d_folders = val_image2d_folders\n",
    "\n",
    "datamodule = CustomDataModule(\n",
    "    train_image3d_folders = train_image3d_folders, \n",
    "    train_image2d_folders = train_image2d_folders, \n",
    "    val_image3d_folders = val_image3d_folders, \n",
    "    val_image2d_folders = val_image2d_folders, \n",
    "    test_image3d_folders = test_image3d_folders, \n",
    "    test_image2d_folders = test_image2d_folders, \n",
    "    batch_size = hparams.batch_size, \n",
    "    shape = hparams.shape\n",
    ")\n",
    "datamodule.setup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomCameras(\n",
    "        dist: float = 3.0, \n",
    "        elev: float = 0.0, \n",
    "        azim: float = 0.0, \n",
    "        batch_size: int = 32, \n",
    "        random: bool = False, \n",
    "        dtype: torch.Tensor = torch.float32,\n",
    "    ): \n",
    "    # R0, T = look_at_view_transform(dist, elev, azim)\n",
    "    if random:\n",
    "        rand = 180*np.random.randint(0, 2)\n",
    "        elev = np.random.uniform( -5,  5) + 180*rand\n",
    "        azim = np.random.uniform( -5,  5) + 180*rand\n",
    "\n",
    "    R, T = look_at_view_transform(dist, elev, azim)\n",
    "    R = R.repeat(batch_size, 1, 1)\n",
    "    T = T.repeat(batch_size, 1)\n",
    "\n",
    "    znear = 0.1 * torch.ones(batch_size) if random else \\\n",
    "            0.1 * torch.ones(batch_size) # 0.5*torch.ones(batch_size) * 10 + 0.1\n",
    "    zfar = 3.5 * torch.ones(batch_size) if random else \\\n",
    "           3.5 * torch.ones(batch_size) # 0.5*torch.ones(batch_size) * 4 + 1 + znear\n",
    "    fov = torch.ones(batch_size) * 60 + (torch.randn(batch_size)) * 5 if random else \\\n",
    "          torch.ones(batch_size) * 60 + 0\n",
    "    aspect_ratio = 1.15 * torch.ones(batch_size) + (torch.randn(batch_size)) * 0.1  if random else \\\n",
    "                   1.15 * torch.ones(batch_size)\n",
    "                   \n",
    "    return FoVPerspectiveCameras(R=R.type(dtype), \n",
    "                                 T=T.type(dtype), \n",
    "                                 znear=znear.type(dtype), \n",
    "                                 zfar=zfar.type(dtype), \n",
    "                                 fov=fov.type(dtype), \n",
    "                                 aspect_ratio=aspect_ratio.type(dtype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VolumeModel(torch.nn.Module):\n",
    "    def __init__(self, renderer, volume_size=[256] * 3, voxel_size=0.1):\n",
    "        super().__init__()\n",
    "        # # After evaluating torch.sigmoid(self.log_colors), we get \n",
    "        # # densities close to zero.\n",
    "        # self.log_densities = torch.nn.Parameter(-4.0 * torch.ones(1, *volume_size))\n",
    "        # # After evaluating torch.sigmoid(self.log_colors), we get \n",
    "        # # a neutral gray color everywhere.\n",
    "        # self.log_colors = torch.nn.Parameter(torch.zeros(3, *volume_size))\n",
    "\n",
    "        self._voxel_size = voxel_size\n",
    "        # Store the renderer module as well.\n",
    "        self._renderer = renderer\n",
    "        \n",
    "    def forward(self, cameras, volumes):\n",
    "        batch_size = cameras.R.shape[0]\n",
    "\n",
    "        # # Convert the log-space values to the densities/colors\n",
    "        # densities = torch.sigmoid(self.log_densities)\n",
    "        # colors = torch.sigmoid(self.log_colors)\n",
    "        \n",
    "        # # Instantiate the Volumes object, making sure\n",
    "        # # the densities and colors are correctly\n",
    "        # # expanded batch_size-times.\n",
    "        # volumes = Volumes(\n",
    "        #     densities = densities[None].expand(\n",
    "        #         batch_size, *self.log_densities.shape),\n",
    "        #     features = colors[None].expand(\n",
    "        #         batch_size, *self.log_colors.shape),\n",
    "        #     voxel_size=self._voxel_size,\n",
    "        # )\n",
    "        \n",
    "        # Given cameras and volumes, run the renderer\n",
    "        # and return only the first output value \n",
    "        # (the 2nd output is a re.5presentation of the sampled\n",
    "        # rays which can be omitted for our purpose).\n",
    "        # return self._renderer(cameras=cameras, volumes=volumes)[0]\n",
    "        # screen_RGBA = screen_RGBA.reshape(B, self.shape, self.shape, 4).permute(0,3,2,1) # 3 for NeRF\n",
    "        screen_RGBA, _ = self._renderer(cameras=cameras, volumes=volumes) #[...,:3]\n",
    "        screen_RGBA = screen_RGBA.permute(0,3,2,1) # 3 for NeRF\n",
    "        screen_RGB = screen_RGBA[:,:3].mean(dim=1, keepdim=True)\n",
    "        normalized = lambda x: (x - x.min())/(x.max() - x.min())\n",
    "        screen_RGB = normalized(screen_RGB)\n",
    "        return screen_RGB"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd0ba7896d619d2e23297155645cc474a0b2bf660f5d50e2d5184ff5ae24a4e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
